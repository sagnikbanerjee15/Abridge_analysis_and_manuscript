#! /usr/bin/env python

from argparse import RawTextHelpFormatter
import argparse 
import logging
import os
import pprint
import sys
import re
import time
import multiprocessing
import random
import glob

def parseCommandLineArguments():
    parser = argparse.ArgumentParser(prog="abridge_reproduce_entire_analysis",description="Program will regenerate all the files, process them and also construct the graphs for publication. Please note that some of the data represents duration of execution and will not be reproducible. But the trend should hold true",formatter_class=RawTextHelpFormatter)
    required_named = parser.add_argument_group('Required arguments')
    optional_named = parser.add_argument_group('Optional arguments')
    
    ##################################################################################################
    # Required arguments
    ##################################################################################################
    required_named.add_argument("-md","--metadata",help="Enter the metadata file. The file format should be same as ListOfNCBI-SRASamplesForExperimentST.csv",required=True)
    required_named.add_argument("-odir","--output_directory",help="Enter the name of the output directory. all analysis will be stored here. Please make sure you have sufficient space on your disk to reproduce all the analysis",required=True)
    required_named.add_argument("--genome","-g",help="Enter the location of the genome",required=True)
    
    ##################################################################################################
    # Optional arguments
    ##################################################################################################
    optional_named.add_argument("--cpu","-n",help="Enter the number of CPUs. Please note that all alignments will be conducted using a single CPU. This argument will control how many parallel alignments can be lanuched", default=1)
    optional_named.add_argument("--num_times","-t",help="Enter the number of times you wish each process to execute. This will be handy in calculating the average time required for compression, decompression, retrieval and other operations", default = 5)
    optional_named.add_argument("--error_directory","-edir",help="Enter a directory where all error files will be stored. If nothing is specified then error files will be stored in the output directory",default=None)
    optional_named.add_argument("--temp_directory","-temp_dir",help="Enter a temporary directory. All files will be dumped in this directory to prevent the output directory to get crowded. Outputs and Error files will not be moved",default = None)
    
    ##################################################################################################
    # Suppressed arguments
    ##################################################################################################
    parser.add_argument("--metadata_expanded","-metadata_expanded",help=argparse.SUPPRESS)
    parser.add_argument("--sra_list_to_be_downloaded","-sra_list_to_be_downloaded",help=argparse.SUPPRESS)
    parser.add_argument("--logfilename","-logfilename",help=argparse.SUPPRESS)# Name of the logfile
     
    return parser.parse_args()

def readMetadataFile(options):
    """
    Reads in the metadata information and restructrues the data
    """
    data = {}
    fhr=open(options.metadata,"r")
    for line in fhr:
        if "Accession" in line:continue
        Organism,Tissue,Layout,Assay_Type,Date_of_publication, Length, Accession,Bioproject,Number_of_reads_or_pairs,Replicate_information, Notes  = line.strip().split(",")
        if Assay_Type not in data:
            data[Assay_Type] = []
        data[Assay_Type].append([Organism,Tissue,Layout,Assay_Type,Date_of_publication, Length, Accession,Bioproject, Number_of_reads_or_pairs,Replicate_information, Notes])
    fhr.close()
    options.metadata_expanded = data
    
def downloadData(options):
    """
    Downloads the data from NCBI-SRA
    """
    options.sra_list_to_be_downloaded = f"{options.output_directory}/sra_list_to_be_downloaded"
    fhw = open(options.sra_list_to_be_downloaded,"w")
    for Assay_Type in options.metadata_expanded:
        for row in options.metadata_expanded[Assay_Type]:
            fhw.write(row[6] + "\n")
    fhw.close()
    
    fhw = open(f"{options.output_directory}/sra_list_to_be_downloaded_temp","w")
    fhr = open(options.sra_list_to_be_downloaded,"r")
    for line in fhr:
        sra = line.strip()
        if os.path.exists(f"{options.temp_directory}/{sra}_1.fastq") == False or os.path.exists(f"{options.temp_directory}/{sra}_2.fastq") == False:
            fhw.write(sra+"\n")
    fhw.close()
    fhr.close()
    
    cmd  = f"downloadAndDumpFastqFromSRA.py "
    cmd += f" --cpu {options.cpu} "
    cmd += f" --sra {options.output_directory}/sra_list_to_be_downloaded_temp "
    cmd += f" --output {options.output_directory}/raw_data "
    cmd += f" 1> {options.output_directory}/outputs/raw_data_download.output "
    cmd += f" 2> {options.output_directory}/errors/raw_data_download.error "
    os.system(cmd)
    
    # Move all files to the temporary directory
    fhr = open(options.sra_list_to_be_downloaded,"r")
    for line in fhr:
        sra = line.strip()
        cmd = f"mv {options.output_directory}/raw_data/{sra}* {options.temp_directory}/ "
        os.system(cmd)
    fhr.close()
    
def configureLogger(options):
    if os.path.exists(options.logfilename)==True:
        os.system(f"rm {options.logfilename}")
    logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S',level=logging.DEBUG, filename=options.logfilename)

def runCommand(eachpinput):
    cmd,dummy = eachpinput
    os.system(cmd)

def mergeReadPairs(eachinput):
    options,sra=eachinput
    pair1_filename = f"{options.output_directory}/raw_data/{sra}_1.fastq"
    pair2_filename = f"{options.output_directory}/raw_data/{sra}_2.fastq"
    merged_filename = f"{options.output_directory}/raw_data/{sra}.fastq"
    if os.path.exists(merged_filename)==True:return
    fhw=open(merged_filename,"w")
    for fhr in [open(pair1_filename,"r") ,open(pair2_filename,"r")]:
        for line_num,line in enumerate(fhr):
            if line_num % 4 == 0 and line[0]=='@' and '/' in line:
                line = line.replace('/','_')
            fhw.write(line)
    fhw.close()

def main():
    commandLineArg=sys.argv
    if len(commandLineArg)==1:
        print("Please use the --help option to get usage information")
    options=parseCommandLineArguments()
    
    os.system(f"mkdir -p {options.output_directory}")
    options.logfilename = options.output_directory+"/progress.log"
    configureLogger(options)
    
    pool = multiprocessing.Pool(processes=int(options.cpu))
    ##################################################################################################
    # Create output directory and subdirectories underneath
    ##################################################################################################
    create_these_directories = [options.output_directory,
                                options.temp_directory,
                                f"{options.output_directory}/raw_data",
                                f"{options.output_directory}/alignments",
                                f"{options.output_directory}/star_index",
                                f"{options.output_directory}/abridge_compressed_files",
                                f"{options.output_directory}/abridge_decompressed_files",
                                f"{options.output_directory}/outputs",
                                f"{options.output_directory}/errors",
                                f"{options.output_directory}/final_output_files",
                                f"{options.output_directory}/final_output_files/graphs"]
    
    for d in create_these_directories:
        os.system(f"mkdir -p {d}")
    
    ##################################################################################################
    # Read in the metadata file
    ##################################################################################################
    readMetadataFile(options)
    logging.info(f"readMetadataFile() execution is complete")
    
    ##################################################################################################
    # Downloading the raw data from NCBI
    ##################################################################################################
    
    downloadData(options)
    logging.info(f"Data download from NCBI is complete")
    
    ##################################################################################################
    # Construct STAR index
    ##################################################################################################
    cmd  = "STAR "
    cmd += f" --runThreadN {options.cpu}"
    cmd += f" --genomeSAindexNbases 12 "
    cmd += f" --genomeDir {options.output_directory}/star_index "
    cmd += f" --genomeFastaFiles {options.genome}"
    cmd += f" --runMode genomeGenerate " 
    if os.path.exists(f"{options.output_directory}/star_index/genomeParameters.txt")==False:
        os.system(cmd)
        logging.info(f"STAR index generation is complete")
    
    ##################################################################################################
    # Construct BWA-MEM index
    ##################################################################################################
    cmd  = f"bwa index "
    cmd += f" -p {options.output_directory}/bwa_index "
    cmd += f" {options.genome} "
    if os.path.exists(f"{options.output_directory}/bwa_index.bwt")==False:
        os.system(cmd)
       
    ##################################################################################################
    # Prepare metadata for alignemnt
    # A single .csv file will be prepared for both SE and PE samples
    # Organism,Tissue,Layout,Assay_Type,Date_of_publication,Read_Length,SRA 
    # Organism,Tissue,Layout,Assay_Type,Date_of_publication, Length, Accession,Bioproject, Number_of_reads_or_pairs,Replicate_information, Notes]
    ##################################################################################################
    fhw = open(f"{options.output_directory}/metadata_for_alignment.csv","w")
    add_these_back_to_metadata_expanded = {}
    for Assay_Type in options.metadata_expanded:
        add_these_back_to_metadata_expanded[Assay_Type] = []
        for row in options.metadata_expanded[Assay_Type]:
            fhw.write(",".join([row[0], #organism
                              row[1], #tissue
                              row[2], #Layout
                              row[3], #Assay_type
                              row[4],
                              row[5],
                              row[6]  
                ])+"\n")
            
            fhw.write(",".join([row[0],
                              row[1],
                              "SE",
                              row[3],
                              row[4],
                              row[5],
                              row[6]  
                ])+"\n")
            add_these_back_to_metadata_expanded[Assay_Type].append([row[0],row[1],"SE",row[3],row[4],row[5],row[6]])
    fhw.close()
    for Assay_Type in options.metadata_expanded:
        options.metadata_expanded[Assay_Type].extend(add_these_back_to_metadata_expanded[Assay_Type])
    logging.info(f"Metadata preparation for alignment is complete")
    
    ##################################################################################################
    # Simulate DNA-Seq reads with ART
    ##################################################################################################
    for iteration in range(5):
        cmd  = f" art_illumina "
        cmd += f" -ss HS25 "
        cmd += f" -i {options.genome}"
        cmd += f" --paired "
        cmd += f" --fcov 10 "
        cmd += f" --insRate  0.0001 "
        cmd += f" --insRate2 0.0002 "
        cmd += f" --delRate  0.0001 "
        cmd += f" --delRate2 0.0002 "
        cmd += f" --maxIndel 10 "
        cmd += f" --len 150 "
        cmd += f" --sdev 50 "
        cmd += f" --mflen 500 " # the mean size of DNA/RNA fragments for paired-end simulations
        cmd += f" --noALN " # do not output ALN alignment file
        cmd += f" --out {options.output_directory}/raw_data/sim_data_{iteration} "
        if os.path.exists(f"{options.output_directory}/raw_data/sim_data_{iteration}")==False:
            os.system(cmd)
    return
    ##################################################################################################
    # Map reads with STAR and BWA
    ##################################################################################################
    cmd  = "align_reads_using_STAR_and_BWA.py "
    cmd += f" --metadata {options.output_directory}/metadata_for_alignment.csv "
    cmd += f" --output_directory {options.output_directory}/alignments "
    cmd += f" --star_genome_index {options.output_directory}/star_index "
    cmd += f" --bwa_genome_index {options.output_directory}/bwa_index "
    cmd += f" --input_location {options.output_directory}/raw_data "
    cmd += f" --cpu 1 "
    cmd += f" --num_times {options.num_times} "
    cmd += f" --temp_directory {options.temp_directory} "
    cmd += f" 1> {options.output_directory}/outputs/alignment.output "
    cmd += f" 2> {options.output_directory}/errors/alignment.error "
    os.system(cmd)
    logging.info(f"Aligning reads with STAR and BWA is complete")
    
    ##################################################################################################
    # Compress alignments with Abridge
    ##################################################################################################
    for iteration in range(int(options.num_times)):
        for Assay_Type in options.metadata_expanded:
            for row in options.metadata_expanded[Assay_Type]:
                sra = row[6]
                layout = row[2]
                alignment_samfilename_in_temp = f"{options.temp_directory}/{sra}_{layout}.sam"
                if os.path.exists(alignment_samfilename_in_temp) == False : continue
                alignment_samfilename = f"{options.output_directory}/star_alignments/{sra}_{layout}.sam"
                cmd = f"cp {alignment_samfilename_in_temp} {alignment_samfilename}"
                os.system(cmd)
            
                cmd  = f"(/usr/bin/time --verbose abridge "
                cmd += f" --compress "
                cmd += f" --cpu 1 "
                cmd += f" --genome {options.genome} "
                cmd += f" --inputsamfilenames {alignment_samfilename} "
                cmd += f" --output_directory {options.output_directory}/abridge_compressed_files/{iteration} "
                cmd += f" --error_directory {options.error_directory}/abridge/{iteration} "
                cmd += f" --keep_intermediate_error_files "
                cmd += f" --both " # Perform both compression - once using 7z and again using brotli (from Google)
                cmd += ")"
                cmd += f" 1> {options.output_directory}/outputs/{sra}_{iteration}_{layout}_compress.output "
                cmd += f" 2> {options.output_directory}/errors/{sra}_{iteration}_{layout}_compress.error " 
                if os.path.exists(f"{options.output_directory}/abridge_compressed_files/{iteration}/{sra}_{layout}.sam.abridge.7z") == True and os.path.exists(f"{options.output_directory}/abridge_compressed_files/{iteration}/{sra}_{layout}.sam.abridge.br") == True : continue
                logging.info(f"Running command - {cmd}")
                os.system(cmd)
                
    ##################################################################################################
    # Decompress alignments with Abridge
    ##################################################################################################
    for iteration in range(int(options.num_times)):
        for Assay_Type in options.metadata_expanded:
            for row in options.metadata_expanded[Assay_Type]:
                sra = row[6]
                layout = row[2]
                alignment_samfilename = f"{options.output_directory}/star_alignments/{sra}_{layout}.sam"
            
                cmd  = f"(/usr/bin/time --verbose abridge "
                cmd += f" --decompress "
                cmd += f" --cpu 1 "
                cmd += f" --genome {options.genome} "
                cmd += f" --inputabrfilenames {options.output_directory}/abridge_compressed_files/{iteration}/{sra}_{layout}.sam.abridge.br "
                cmd += f" --output_directory {options.output_directory}/abridge_decompressed_files/{iteration} "
                cmd += f" --error_directory {options.error_directory}/abridge/{iteration} "
                cmd += f" --keep_intermediate_error_files "
                cmd += ")"
                cmd += f" 1> {options.output_directory}/outputs/{sra}_{iteration}_{layout}_decompress.output "
                cmd += f" 2> {options.output_directory}/errors/{sra}_{iteration}_{layout}_decompress.error " 
                if os.path.exists(f"{options.output_directory}/abridge_compressed_files/{iteration}/{sra}_{layout}.decompress.sam") == True : continue
                logging.info(f"Running command - {cmd}")
                os.system(cmd)
    

if __name__ == "__main__":
    main()
    
    
    
    
    